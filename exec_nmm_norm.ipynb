{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, gc, json\n",
    "import util.trainer as tr\n",
    "import torch.nn\n",
    "from torch.utils.data import DataLoader\n",
    "from util.input_data import Dataset\n",
    "from util.AdaBound import AdaBound\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def exec_model(\n",
    "    scale,\n",
    "    model_type,\n",
    "    comment='',\n",
    "    lr = 1e-5,\n",
    "    wd = 1e-7,\n",
    "    tries = 1,\n",
    "    root_model = 'd:/MODELS/202204/nmm',\n",
    "    root_data  = 'c:/WORKSPACE_KRICT/DATA/data_snu',\n",
    "    num_epochs = 300,\n",
    "    batch_size = 128,\n",
    "    train_ratio = 0.7,\n",
    "    valid_ratio = 0.2,\n",
    "    metal_ratio = 1,\n",
    "):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    dataset = Dataset()\n",
    "    dataset.load_dataset(os.path.join(root_data, f'inputdata_{scale}.pickle'), silent=True)\n",
    "\n",
    "    for n in range(0, tries):\n",
    "        rseed  = 35 + n\n",
    "        train_data, valid_data, test_data = dataset.train_test_split(train_ratio=train_ratio, \n",
    "                                                                     valid_ratio=valid_ratio,\n",
    "                                                                     rseed=rseed)\n",
    "        train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, \n",
    "                                    collate_fn=tr.collate_fn)\n",
    "        val_data_loader = DataLoader(valid_data, batch_size=batch_size, collate_fn=tr.collate_fn)\n",
    "        test_data_loader = DataLoader(test_data, batch_size=batch_size, collate_fn=tr.collate_fn)\n",
    "\n",
    "        model = DistNN(dataset.n_atom_feats, dataset.n_rdf_feature, dataset.n_bdf_feature).cuda()\n",
    "        optimizer = AdaBound(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        criterion = torch.nn.L1Loss()\n",
    "\n",
    "        for i in range(99):\n",
    "            root = os.path.join(root_model, model_type)\n",
    "            if not os.path.isdir(root):\n",
    "                os.makedirs(root)\n",
    "            if '{}_{:02d}'.format(scale, i) not in ' '.join(os.listdir(root)):\n",
    "                output_root = os.path.join(root, '{}_{:02d}'.format(scale, i))\n",
    "                if len(comment) > 0: output_root += f'_{comment}'\n",
    "                os.makedirs(output_root)\n",
    "                break\n",
    "        print(output_root)\n",
    "        with open(os.path.join(output_root, 'params.json'),'w') as f:\n",
    "            json.dump(dict(random_seed=rseed, learning_rate=lr, weight_decay=wd, \n",
    "                train_ratio=train_ratio, valid_ratio=valid_ratio, batch_size=batch_size), \n",
    "                f, indent=4)\n",
    "        writer = SummaryWriter(output_root)\n",
    "        #with torch.no_grad():\n",
    "        #    dummy = iter(test_data_loader).next()\n",
    "        #    writer.add_graph(model, dummy[:7])\n",
    "\n",
    "        for epoch in range(1, num_epochs+1):\n",
    "            train_loss, train_mae, train_f1 = tr.train(model, optimizer, train_data_loader, criterion)\n",
    "            val_loss, val_mae, val_f1, _, _, _ = tr.test(model, val_data_loader, criterion)\n",
    "            if epoch > 20 and train_loss > 1: \n",
    "                break\n",
    "            print('Epoch [{}/{}]\\tTrain loss: {:.4f}\\tVal loss: {:.4f} ({:.4f})'\n",
    "                    .format(epoch, num_epochs, train_loss, val_loss, val_f1))\n",
    "\n",
    "            writer.add_scalar('train/loss', train_loss, epoch)\n",
    "            writer.add_scalar('train/MAE', train_mae, epoch)\n",
    "            writer.add_scalar('train/F1', train_f1, epoch)\n",
    "            writer.add_scalar('valid/loss', val_loss, epoch)\n",
    "            writer.add_scalar('valid/MAE', val_mae, epoch)\n",
    "            writer.add_scalar('valid/F1', val_f1, epoch)\n",
    "\n",
    "            if epoch%20 == 0:\n",
    "                torch.save(model.state_dict(), \n",
    "                           os.path.join(output_root, 'model.{:05d}.pt'.format(epoch)))\n",
    "                _, _, _, idxs, targets, preds = tr.test(model, test_data_loader, criterion)\n",
    "                np.savetxt(os.path.join(output_root, 'pred.{:05d}.txt'.format(epoch)), \n",
    "                           np.hstack([idxs, targets, preds]), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:/MODELS/202204/nmm\\M02\\metal_TTT_02_L1_2L1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\WORKSPACE_KRICT\\CODES\\band_gap_model\\new_model.metal\\util\\AdaBound.py:91: UserWarning: This overload of add is deprecated:\n",
      "\tadd(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd(Tensor other, *, Number alpha) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:1050.)\n",
      "  grad = grad.add(group['weight_decay'], p.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300]\tTrain loss: 2.3878\tVal loss: 1.7253 (0.6781)\n",
      "Epoch [2/300]\tTrain loss: 1.2495\tVal loss: 1.0158 (0.8651)\n",
      "Epoch [3/300]\tTrain loss: 0.9673\tVal loss: 0.9726 (0.8641)\n",
      "Epoch [4/300]\tTrain loss: 0.9060\tVal loss: 0.9453 (0.8861)\n",
      "Epoch [5/300]\tTrain loss: 0.8897\tVal loss: 0.8940 (0.8838)\n",
      "Epoch [6/300]\tTrain loss: 0.8605\tVal loss: 0.8794 (0.8913)\n",
      "Epoch [7/300]\tTrain loss: 0.8379\tVal loss: 1.4117 (0.8604)\n",
      "Epoch [8/300]\tTrain loss: 0.8154\tVal loss: 0.9827 (0.8946)\n",
      "Epoch [9/300]\tTrain loss: 0.7684\tVal loss: 0.8269 (0.8987)\n",
      "Epoch [10/300]\tTrain loss: 0.7469\tVal loss: 0.9546 (0.8680)\n",
      "Epoch [11/300]\tTrain loss: 0.7615\tVal loss: 0.7964 (0.9032)\n",
      "Epoch [12/300]\tTrain loss: 0.7251\tVal loss: 0.8783 (0.8788)\n",
      "Epoch [13/300]\tTrain loss: 0.7116\tVal loss: 0.8570 (0.8882)\n",
      "Epoch [14/300]\tTrain loss: 0.7096\tVal loss: 0.7383 (0.9031)\n",
      "Epoch [15/300]\tTrain loss: 0.6768\tVal loss: 0.8938 (0.8752)\n",
      "Epoch [16/300]\tTrain loss: 0.6700\tVal loss: 0.7012 (0.9175)\n",
      "Epoch [17/300]\tTrain loss: 0.6552\tVal loss: 0.7047 (0.9131)\n",
      "Epoch [18/300]\tTrain loss: 0.6367\tVal loss: 0.7846 (0.8983)\n",
      "Epoch [19/300]\tTrain loss: 0.6156\tVal loss: 0.7394 (0.9048)\n",
      "Epoch [20/300]\tTrain loss: 0.6081\tVal loss: 0.6933 (0.9119)\n",
      "Epoch [21/300]\tTrain loss: 0.5910\tVal loss: 0.6574 (0.9171)\n",
      "Epoch [22/300]\tTrain loss: 0.5828\tVal loss: 0.7022 (0.9161)\n",
      "Epoch [23/300]\tTrain loss: 0.5723\tVal loss: 0.9099 (0.8940)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\ex01\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\ex01\\lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\", line 233, in run\n",
      "    self._record_writer.write(data)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\ex01\\lib\\site-packages\\tensorboard\\summary\\writer\\record_writer.py\", line 40, in write\n",
      "    self._writer.write(header + header_crc + data + footer_crc)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\ex01\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 519, in write\n",
      "    self.fs.append(self.filename, file_content, self.binary_mode)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\ex01\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 150, in append\n",
      "    self._write(filename, file_content, \"ab\" if binary_mode else \"a\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\ex01\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 154, in _write\n",
      "    with io.open(filename, mode, encoding=encoding) as f:\n",
      "PermissionError: [Errno 13] Permission denied: b'd:/MODELS/202204/nmm\\\\M02\\\\metal_TTT_02_L1_2L1\\\\events.out.tfevents.1649649724.DESKTOP-2O9BLGO.13560.0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/300]\tTrain loss: 0.5649\tVal loss: 0.9589 (0.8837)\n",
      "Epoch [25/300]\tTrain loss: 0.5727\tVal loss: 0.7147 (0.9100)\n"
     ]
    }
   ],
   "source": [
    "from model.model_02 import DistNN\n",
    "import util.trainer_clas as tr\n",
    "\n",
    "exec_model(scale='metal_TTT', model_type='M02', comment='L1_2L1')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cfb2e760b55082f7e18274ad9b6beeb89af4df0a5c88a9ce379e413b137aeb47"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ex01')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
