{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tgnn.model.TGNN import TGNN as TGNNR\n",
    "from tgnn.model.TGNN import TGNNX\n",
    "from tgnn.model.CGCNN import CGCNN as CGCNNX\n",
    "from tgnn.model.CGCNN import CGCNNR \n",
    "import tgnn.util.trainer as tr\n",
    "import tgnn.util.crystal_conv as cc\n",
    "from torch.utils.data import DataLoader\n",
    "import os, torch, gc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "model_root = 'C:/WORKSPACE_KRICT/MODELS/202204/baseline'\n",
    "root_data  = 'C:/WORKSPACE_KRICT/DATA/data_snu/with_metal'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2019/2019 [01:10<00:00, 28.80it/s]\n",
      "100%|██████████| 2019/2019 [00:14<00:00, 141.58it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cc.load_mat_atom_feats()\n",
    "\n",
    "dataset = cc.load_dataset(root_data, fn='id_target.test.baseline.csv', target_idx=3, ref_idx=1, \n",
    "                radius=4, test_only=True, model_type='tgnn')\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=1, collate_fn=tr.collate)\n",
    "\n",
    "for mtype, ModelObject in [('tgnn_x',TGNNX), ('tgnn_r',TGNNR)]:\n",
    "    model_type_path = os.path.join(model_root, mtype)\n",
    "    for model_name in os.listdir(model_type_path):\n",
    "        output_root = os.path.join(model_type_path, model_name)\n",
    "        model = ModelObject(cc.num_atom_feats, cc.num_bond_feats, 1)\n",
    "        \n",
    "        pts = []\n",
    "        for pt in os.listdir(output_root):\n",
    "            if not pt.endswith('.pt'): continue\n",
    "            pts.append(pt)\n",
    "        pts = sorted(pts)\n",
    "        model_path = os.path.join(output_root, pts[-1])\n",
    "        epoch = int(pts[-1].split('.')[1])\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.cuda()\n",
    "        \n",
    "        _, _, idxs, targets, preds = tr.test(model, data_loader, torch.nn.L1Loss())\n",
    "        df = pd.DataFrame(dict(\n",
    "            icsd_id=idxs.astype(int).squeeze(), \n",
    "            target=targets.squeeze(), \n",
    "            prediction=preds.squeeze()))\n",
    "        df = df.sort_values('icsd_id')\n",
    "        df.to_csv(os.path.join(output_root, 'test.{:05d}.csv'.format(epoch)), index=False)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "dataset = cc.load_dataset(root_data, fn='id_target.test.baseline.csv', target_idx=3, ref_idx=1, \n",
    "                radius=8, test_only=True, model_type='cgcnn')\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=2048, collate_fn=tr.collate_cgcnn)\n",
    "\n",
    "for mtype, ModelObject in [('cgcnn_x',CGCNNX), ('cgcnn_r',CGCNNR)]:\n",
    "    model_type_path = os.path.join(model_root, mtype)\n",
    "    for model_name in os.listdir(model_type_path):\n",
    "        output_root = os.path.join(model_type_path, model_name)\n",
    "        model = ModelObject(cc.num_atom_feats, cc.num_edge_feats, 1)\n",
    "        \n",
    "        pts = []\n",
    "        for pt in os.listdir(output_root):\n",
    "            if not pt.endswith('.pt'): continue\n",
    "            pts.append(pt)\n",
    "        pts = sorted(pts)\n",
    "        model_path = os.path.join(output_root, pts[-1])\n",
    "        epoch = int(pts[-1].split('.')[1])\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.cuda()\n",
    "        \n",
    "        _, _, idxs, targets, preds = tr.test(model, data_loader, torch.nn.L1Loss())\n",
    "        df = pd.DataFrame(dict(\n",
    "            icsd_id=idxs.astype(int).squeeze(), \n",
    "            target=targets.squeeze(), \n",
    "            prediction=preds.squeeze()))\n",
    "        df = df.sort_values('icsd_id')\n",
    "        df.to_csv(os.path.join(output_root, 'test.{:05d}.csv'.format(epoch)), index=False)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model.00000.pt', 'model.00020.pt', 'model.00040.pt', 'model.00060.pt', 'model.00080.pt', 'model.00100.pt', 'model.00120.pt', 'model.00140.pt', 'model.00160.pt', 'model.00180.pt', 'model.00200.pt', 'model.00220.pt', 'model.00240.pt', 'model.00260.pt', 'model.00280.pt']\n",
      "['model.00000.pt', 'model.00020.pt', 'model.00040.pt', 'model.00060.pt', 'model.00080.pt', 'model.00100.pt', 'model.00120.pt', 'model.00140.pt', 'model.00160.pt', 'model.00180.pt', 'model.00200.pt', 'model.00220.pt', 'model.00240.pt', 'model.00260.pt', 'model.00280.pt']\n",
      "['model.00020.pt', 'model.00040.pt', 'model.00060.pt', 'model.00080.pt', 'model.00100.pt', 'model.00120.pt', 'model.00140.pt', 'model.00160.pt', 'model.00180.pt', 'model.00200.pt', 'model.00220.pt', 'model.00240.pt', 'model.00260.pt', 'model.00280.pt', 'model.00300.pt']\n",
      "['model.00020.pt', 'model.00040.pt', 'model.00060.pt', 'model.00080.pt', 'model.00100.pt', 'model.00120.pt', 'model.00140.pt', 'model.00160.pt', 'model.00180.pt', 'model.00200.pt', 'model.00220.pt', 'model.00240.pt', 'model.00260.pt', 'model.00280.pt', 'model.00300.pt']\n"
     ]
    }
   ],
   "source": [
    "for mn in os.listdir(model_type_path):\n",
    "    mp = os.path.join(model_type_path, mn)\n",
    "    pts = [fn for fn in os.listdir(mp) if fn.endswith('.pt')]\n",
    "    print(pts)\n",
    "    print(sorted(pts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18605/18605 [05:53<00:00, 52.62it/s] \n",
      "100%|██████████| 10387/10387 [03:55<00:00, 44.03it/s]\n"
     ]
    }
   ],
   "source": [
    "_ = cc.load_dataset(root_data, fn='id_target.csv', target_idx=3, ref_idx=1, \n",
    "                radius=0.8, model_type='cgcnn', save_ids=True)\n",
    "jn = 'C:/WORKSPACE_KRICT/MODELS/202204/baseline/ids.json'\n",
    "os.rename(jn, jn.replace('ids.json','ids.metal.json'))\n",
    "_ = cc.load_dataset(root_data, fn='id_target.ins.csv', target_idx=3, ref_idx=1, \n",
    "                radius=1, model_type='cgcnn', save_ids=True)\n",
    "jn = 'C:/WORKSPACE_KRICT/MODELS/202204/baseline/ids.json'\n",
    "os.rename(jn, jn.replace('ids.json','ids.ins.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "df = pd.read_csv('C:/WORKSPACE_KRICT/DATA/data_snu/with_metal/id_target.csv')\n",
    "\n",
    "\n",
    "ndim = 800000\n",
    "with open('C:/WORKSPACE_KRICT/MODELS/202204/baseline/ids.metal.json') as f:\n",
    "    mids = json.load(f)\n",
    "with open('C:/WORKSPACE_KRICT/MODELS/202204/baseline/ids.ins.json') as f:\n",
    "    iids = json.load(f)\n",
    "\n",
    "amask = np.zeros((ndim), dtype=bool)\n",
    "mmask = np.zeros((ndim), dtype=bool)\n",
    "imask = np.zeros((ndim), dtype=bool)\n",
    "amask[np.array(df.icsd_number)] = True\n",
    "mmask[np.array(mids['train']).astype(int)] = True\n",
    "mmask[np.array(mids['valid']).astype(int)] = True\n",
    "imask[np.array(iids['train']).astype(int)] = True\n",
    "imask[np.array(iids['valid']).astype(int)] = True\n",
    "\n",
    "not_seen_mask = amask & ~ mmask & ~imask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.read_csv('C:/WORKSPACE_KRICT/DATA/data_snu/with_metal/id_target.test.csv')\n",
    "tmask = np.zeros((ndim), dtype=bool)\n",
    "tmask[np.array(dft.icsd_number)] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gga_metal = np.zeros((ndim), dtype=bool)\n",
    "gga_metal[df[df.gap_gga == 0].icsd_number] = True\n",
    "hse_metal = np.zeros((ndim), dtype=bool)\n",
    "hse_metal[df[df.gap_hse == 0].icsd_number] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(not_seen_mask & gga_metal), np.sum(not_seen_mask & hse_metal), np.sum(not_seen_mask & gga_metal & ~hse_metal), np.sum(not_seen_mask & gga_metal & ~hse_metal & tmask)\n",
    "#icsd_ids = np.arange(ndim)[not_seen_mask]\n",
    "\n",
    "#df_mask = [icsd in icsd_ids for icsd in df.icsd_number]\n",
    "df[df_mask].to_csv('C:/WORKSPACE_KRICT/DATA/data_snu/with_metal/id_target.test.baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 13.44it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = cc.load_dataset(root_data, fn='id_target.subset.csv', target_idx=3, ref_idx=1, \n",
    "                radius=4, test_only=True, model_type='tgnn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'16'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cfb2e760b55082f7e18274ad9b6beeb89af4df0a5c88a9ce379e413b137aeb47"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ex01')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
